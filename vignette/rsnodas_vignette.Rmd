---
title: "rsnodas vignette"
author: Logan Schneider
date: "July 12, 2022"
output: 
    bookdown::pdf_document2:
    includes:
    number_sections: TRUE
fontsize: 11pt
header-includes:
  - \usepackage{amsmath}
  - \usepackage{hyperref}
  - \usepackage{url}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \usepackage{xcolor}
  - \newcommand*{\nspace}{\vspace{0.3cm}}
---


\newpage 

```{r setup, include=FALSE}
# for more options see the recording of class
# - https://bookdown.org/yihui/rmarkdown-cookbook/hide-one.html
knitr::opts_chunk$set(echo = FALSE, warning = FALSE,
                      message = FALSE, results = TRUE)
'%>%' <- magrittr::'%>%'
library(rsnodas)
library(ggplot2)
```



# Introduction
This rsnodas package allows users to access, clean, visualize, and analyze data from the following sources:
\begin{itemize}
\item \href{https://nsidc.org/data/g02158}{\textcolor{blue}{Snow Data Assimulation System} (SNODAS)}
\item \href{https://nsidc.org/data/nsidc-0719}{\textcolor{blue}{University of Arizona} (UA)}
\item \href{https://prism.oregonstate.edu/}{\textcolor{blue}{Parameter-elevation Regressions on Independent Slopes Model} (PRISM)}
\item \href{https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-dailyGlobal}{\textcolor{blue}{Historical Climatology Network daily} (GHCND)} which provides access to Snow Telemetry (SNOTEL) stations
\end{itemize}

SNODAS, UA, and PRISM provide data in the form of gridded rasters for the contiguous United States. Each source can have different spatial resolutions like 800m, 1km, or 4km and multiple temporal scales of daily, monthly, annual, and 30 year normals. GHCND provides in-situ measurements, spatial point data, with different temporal scales.  This package focuses on downloading the daily measurements.  Please refer to their webpages for more information about each data product. 


## Installation
rsnodas is available on GitHub and can be installed with devtools:

```{r install, eval = FALSE, echo = TRUE}
# install.packages("devtools")
library(devtools)
install_github("lschneider93/rsnodas")
```

<!-- \url{https://www.usu.edu/utahsnowload/}. -->

The outline for understanding rsnodas capabilities is as follows:
\begin{enumerate}
  \item Download SNODAS
  \item Download SNOTEL and PRISM
  \item GAM to Raster
  \begin{enumerate}
    \item Station Density
  \end{enumerate}
  \item Ensemble
\end{enumerate}

# Downloading SNODAS
SNODAS provides maps of the following data:

\begin{itemize}
\item Snow water equivalent (SWE) 
\item Snow Depth (SnD)
\item Snow melt runoff (SM)
\item Sublimation from the Snow Pack (SSP)
\item Sublimation of Blowing Snow (SBS)
\item Solid and liquid precipitation (PPT)
\item Snow pack average temperature (SPTave)
\end{itemize}

The function `format_date` will create a character vector with each element being a different day in the format YYYY-MM-DD that most functions require. This function can be used inside other functions to allow for mass downloading specific dates of a year. The function `download_snodas_data` is one example in which this function will be applicable

<!-- has the arguments of `dates`, `masked`, `remove_zip`, `data_saved`, `out_dir`, and `GTiff`. The user can specify which or all of the 8 options of data to download, where to store, and if they want to save the map as a tif.  -->

```{r fdates, echo = FALSE, eval = FALSE}

# This will download all SNODAS for April 1st in 2011-2014
download_snodas(dates = format_dates(day = 1, month = 4, year = 2011:2014),
                masked = TRUE, overwrite = TRUE, remove_zip = FALSE,
                                 data_saved = c('swe', 'SP', "SD", "SPT",
                                                'bss', 'melt', 'SPS', 'NSP'),
                                 out_dir = "C:/Users/Logan/Desktop/GitHub/snodas_data",
                                 GTiff = TRUE) 

# This will download SWE and Snow depth for the 2nd-3rd of October, November and December in 2007
download_snodas(dates = format_dates(day = 2:3, month = 10:12, year = 2007),
                masked = TRUE, overwrite = TRUE, remove_zip = FALSE,
                                 data_saved = c('swe', "SD"),
                                 out_dir = "C:/Users/Logan/Desktop/GitHub/snodas_data",
                                 GTiff = TRUE) 
```


<!-- \newpage -->

```{r snodas, echo = TRUE, eval = FALSE}
# Download Snodas SWE data for April 1st in 2014 and 2015
snodas_april1 <- download_snodas(dates = format_dates(day = 1,
                                                           month = 4,
                                                           year = 2014:2015),
                                      masked = TRUE,
                                      remove_zip = TRUE,
                                      data_saved = c("swe"),
                                      out_dir = "C:/Users/Logan/Desktop/GitHub/snodas_data",
                                      GTiff = FALSE)

# get the pipe function from magrittr
"%>%" <- magrittr::"%>%"

# Get an shape of utah from the maps package
ut_map <- maps::map("state", plot = FALSE, fill = TRUE) %>%
  sf::st_as_sf() %>%
  dplyr::filter(ID == "utah") %>%
  sf::st_transform(crs = sf::st_crs(snodas_april1$'swe_2014-04-01'))

# Crop the maps to just the state of Utah
snodas_ut_2014 <- sf::st_crop(snodas_april1$'swe_2014-04-01', ut_map)

# Change the name so text file isn't seen when plotting
names(snodas_ut_2014) <- "Value"

# Plot SNODAS April 1st 2015 SWE map of Utah with blue outline
g <- ggplot() + 
  stars::geom_stars(data = snodas_ut_2014) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2014 SNODAS SWE predictions") + 
  scale_fill_viridis_c(option = "A") + 
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        text = element_text(size = 22))
g
```

<!-- \begin{figure}[ht] -->
<!-- \centerline{\includegraphics[width=.50\textwidth]{figures/Thesis_SNODAS_map_for_2014.png}} -->
<!-- \caption{\label{SNODAS SWE predictions for April 1st, 2015.} -->
<!-- \small -->
<!-- This is a gridded estimates of SWE throughout the state of Utah with a blue boarder. -->
<!-- } -->
<!-- \end{figure} -->



# Download SNOTEL and PRISM

## Downloading SNOTEL site data

The `data-raw` folder contains an script titled `DATASET` that shows how to download the all SNOTEL data by using `download_all_ghcnd_stations`.  Note that there is more than 30 gigabytes of data and this will take time to download. The functions `download_all_ghcnd_stations` and `download_all_ghcnd_stations` are for the purpose of sifting through all the data to get the stations in a specific state.  These functions were used to create the dataset `april_1_snotel_data`. 
```{r snotel, eval = FALSE, echo = TRUE}
# Code to download all stations in your working directory. A file path could 
#   have been used instead of ".".
download_all_ghcnd_stations(directory = ".")

# april 1st data for SNOTEL stations in Utah
snotel_ut <- rsnodas::april_1_snotel_data

# subset to just April 1st, 2015.
snotel_ut_2014 <- snotel_ut[snotel_ut$DATE == "2014-04-01", ]

```

## Downloading PRISM climate data

The PRISM climate group has been provided maps since 1895 for the following climate elements:
\begin{itemize}
\item Precipitation (PPT)
\item Minimum and maximum temperature (Tmin and Tmax)
\item Minimum and maximum vapor pressure deficit (vpdmin and vpdmax)
\item mean dew point (tdmean)
\item Elevation (Elev)
\item Total global shortwave solar radiation
\end{itemize}

Most of this data can be downloaded by utilizing the R package, \texttt{prism}, and more examples and information is available at \href{https://cran.r-project.org/web/packages/prism/vignettes/prism.html}{\textcolor{blue}{this link}. The function `download_prism` can be used to download and store PRISM climate data that can be utilized later for model prediction. These are examples of downloading daily, monthly, and yearly data from separate years and multiple types.

```{r prism, eval = FALSE}
prism::prism_set_dl_dir(paste0(getwd(), "/data-raw/prism"))

# Download the 4km resolution of the 30-year average precipitation for the months of March and April
prism::get_prism_normals(type = "ppt", resolution = "4km",
                         mon = 3:4, keepZip = FALSE)

# Download the 30-year annual average precip and annual average temperature
prism::get_prism_normals("ppt", "4km", annual = TRUE, keepZip = FALSE)

```

```{r prism2, eval = FALSE}
## NOT RUN, This was ran earlier 
# Example of downloading 4km monthly precipitation maps from Dec. 2013 - Feb. 2014 
download_prism(sp_res = "4km", data = c("ppt"), t_res = "monthly",
               start_date = as.Date("2013-12-01"), end_date = as.Date("2014-02-15"),  
               out_dir = "C:/Users/Logan/Desktop/GitHub/prism")

# Example of downloading daily 4km mean and max temperature maps for Jan. 1-2, 2004
download_prism(sp_res = "4km", data = c("tmax", "tmean"), t_res = "daily",
               start_date = as.Date("2004-01-01"), end_date = as.Date("2004-01-02"),
               out_dir = "C:/Users/Logan/Desktop/GitHub/prism")

# Example of downloading yearly Daily minimum and max vapor pressure deficit 
#   at 4km resolution maps for Jan. 1, 2017-2019
download_prism(sp_res = "4km", data = c("vpdmin", "vpdmax"), t_res = "yearly", 
               start_date = as.Date("2017-01-01"), end_date = as.Date("2019-01-15"),
               out_dir = "C:/Users/Logan/Desktop/GitHub/prism")

```

# GAM to Raster

After downloading the point data provided by SNOTEL sites and climate variables from PRISM.  The process of creating gridded raster estimates will be demonstrated.  This uses the function, `gam_to_raster`.

```{r gam, eval = FALSE}

gam_to_raster(model_data = snotel_ut_2014,
              raster_template = snodas_ut_2014,
              path_to_prism = "C:/Users/Logan/Desktop/GitHub/prism",
              model_x <- c("ppt_normal_annual", "tmean_2013_11_15",
                           "slope", "ELEVATION"),
              model_y <- c("VALUE")
              coords = c("LONGITUDE", "LATITUDE")
```

## Creating gridded estimates from point data

One functionality is the creation of a grid of predictions using precipitation and elevation. This also allows the user to input a model, that only uses 30-year PRISM normal variables.

```{r gam2, eval = FALSE}
gam_2015 <- rsnodas::gam_to_raster(model_data = snotel_ut_2015,
    raster_template = snodas_ut_2015,
    path_to_prism = "/Users/loganschneider/Desktop/PRISM")

ggplot() +
  stars::geom_stars(data = gam_2015) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2015 GAM SWE predictions") +
  scale_fill_viridis_c(option = "D") +
  theme(plot.title = element_text(hjust = 0.5, size = 20),
        text = element_text(size = 16))
```
