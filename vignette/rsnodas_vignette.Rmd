---
title: "rsnodas vignette"
author: Logan Schneider
date: "July 12, 2022"
output: 
    bookdown::pdf_document2:
    includes:
    number_sections: TRUE
fontsize: 10pt
header-includes:
  - \usepackage{amsmath}
  - \usepackage{hyperref}
  - \usepackage{url}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \usepackage{xcolor}
  - \newcommand*{\nspace}{\vspace{0.3cm}}
---


\newpage 

```{r setup, include=FALSE}
# for more options see the recording of class
# - https://bookdown.org/yihui/rmarkdown-cookbook/hide-one.html
knitr::opts_chunk$set(echo = FALSE, warning = FALSE,
                      message = FALSE, results = TRUE)
'%>%' <- magrittr::'%>%'
library(rsnodas)
library(ggplot2)
```



# Introduction
This rsnodas package allows users to access, clean, visualize, and analyze data from the following sources:
\begin{itemize}
\item \href{https://nsidc.org/data/g02158}{\textcolor{blue}{Snow Data Assimulation System} (SNODAS)}
\item \href{https://nsidc.org/data/nsidc-0719}{\textcolor{blue}{University of Arizona} (UA)}
\item \href{https://prism.oregonstate.edu/}{\textcolor{blue}{Parameter-elevation Regressions on Independent Slopes Model} (PRISM)}
\item \href{https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-dailyGlobal}{\textcolor{blue}{Historical Climatology Network daily} (GHCND)} which provides access to Snow Telemetry (SNOTEL) stations
\end{itemize}

SNODAS, UA, and PRISM provide data in the form of gridded rasters for the contiguous United States. Each source can have different spatial resolutions like 800m, 1km, or 4km and multiple temporal scales of daily, monthly, annual, and 30 year normals. GHCND provides in-situ measurements, spatial point data, with different temporal scales.  This package focuses on downloading the daily measurements.  Please refer to their webpages for more information about each data product. 


## Installation
rsnodas is available on GitHub and can be installed with devtools:

```{r install, eval = FALSE, echo = TRUE}
# install.packages("devtools")
library(devtools)
install_github("lschneider93/rsnodas")
```

<!-- \url{https://www.usu.edu/utahsnowload/}. -->

The outline will be Downloading SNODAS, SNOTEL, and PRISM.  After downloading all of those sources of data, the process of creating a raster of predictions and calculating station density will be shown.  The blending of SNODAS and the Generalized Additive model can then be explored.
<!-- \begin{enumerate} -->
<!--   \item Download SNODAS -->
<!--   \item Download SNOTEL and PRISM -->
<!--   \item GAM to Raster -->
<!--   \begin{enumerate} -->
<!--     \item Station Density -->
<!--   \end{enumerate} -->
<!--   \item Ensemble -->
<!-- \end{enumerate} -->

# Downloading Download SNODAS, SNOTEL and PRISM

## SNODAS
SNODAS provides maps of Snow water equivalent (SWE), Snow Depth (SnD), Snow melt runoff (SM), Sublimation from the Snow Pack (SSP), Sublimation of Blowing Snow (SBS), Solid and liquid precipitation (PPT), and Snow pack average temperature (SPTave). `download_snodas` allows us to choose the variables we want to download. Note that the dates need to be in 'YYYY-MM-DD' or 'YYYY-M-D' format.  The function `format_date` can be used to create character vectors in the needed format to help quickly for mass downloading.

<!-- has the arguments of `dates`, `masked`, `remove_zip`, `data_saved`, `out_dir`, and `GTiff`. The user can specify which or all of the 8 options of data to download, where to store, and if they want to save the map as a tif.  -->
```{r fdates, echo = FALSE, eval = FALSE}

# This will download all SNODAS for April 1st in 2011-2014
download_snodas(dates = format_dates(day = 1, month = 4, year = 2011:2014),
                masked = TRUE, overwrite = TRUE, remove_zip = FALSE,
                                 data_saved = c('swe', 'SP', "SD", "SPT",
                                                'bss', 'melt', 'SPS', 'NSP'),
                                 out_dir = "/Users/loganschneider/Desktop/GitHub/rsnodas/vignette/snodas_data",
                                 GTiff = TRUE) 

# This will download SWE and Snow depth for the 2nd-3rd of October, November and December in 2007
download_snodas(dates = format_dates(day = 2:3, month = 10:12, year = 2007),
                masked = TRUE, overwrite = TRUE, remove_zip = FALSE,
                                 data_saved = c('swe', "SD"),
                                 out_dir = "/Users/loganschneider/Desktop/GitHub/rsnodas/vignette/snodas_data",
                                 GTiff = TRUE) 
```

<!-- \newpage -->

<!-- # get the pipe function from magrittr -->
<!-- "%>%" <- magrittr::"%>%" -->

<!-- # Get an shape of utah from the maps package -->
<!-- ut_map <- maps::map("state", plot = FALSE, fill = TRUE) %>% -->
<!--   sf::st_as_sf() %>% -->
<!--   dplyr::filter(ID == "utah") %>% -->
<!--   sf::st_transform(crs = sf::st_crs(snodas_april1$'swe_2014-04-01')) -->

<!-- # Crop the maps to just the state of Utah -->
<!-- snodas_ut_2014 <- sf::st_crop(snodas_april1$'swe_2014-04-01', ut_map) -->

<!-- # Change the name so text file isn't seen when plotting -->
<!-- names(snodas_ut_2014) <- "Value" -->

```{r snodas, echo = TRUE, eval = FALSE}
# Download Snodas SWE data for April 1st in 2014 and 2015
snodas_april1 <- download_snodas(dates = format_dates(day = 1,
                                                           month = 4,
                                                           year = 2014:2015),
                      masked = TRUE,
                      remove_zip = TRUE,
                      data_saved = c("swe"),
                      out_dir = paste0("/Users/loganschneider/Desktop/GitHub",
                                       "/rsnodas/vignette/snodas_data"),
                      GTiff = FALSE)
```

After downloading SNODAS, you can crop it to the area or state of interest.  These steps aren't shown but this map was cropped to the state of Utah.

```{r snodas2, echo = TRUE, eval = FALSE}
# Plot SNODAS April 1st 2015 SWE map of Utah with blue outline
g <- ggplot() + 
  stars::geom_stars(data = snodas_ut_2014) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2014 SNODAS SWE predictions") + 
  scale_fill_viridis_c(option = "A") + 
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        text = element_text(size = 22))
```

\begin{figure}[ht]
\centerline{\includegraphics[width=.45\textwidth]{figures/Thesis_SNODAS_map_2014.png}}
\end{figure}

## Download SNOTEL 
The `data-raw` folder contains an script titled `DATASET` that shows how to download the all SNOTEL data by using `download_all_ghcnd_stations`.  Note that there is more than 30 gigabytes of data and this will take time to download. The functions `download_all_ghcnd_stations` and `download_all_ghcnd_stations` are for the purpose of sifting through all the data to get the stations in a specific state.  These functions were used to create the dataset `april_1_snotel_data`. 

```{r snotel, eval = FALSE, echo = TRUE}
# Code to download all stations in your working directory. A file path could 
#   have been used instead of ".".
download_all_ghcnd_stations(directory = ".")

# april 1st data for SNOTEL stations in Utah and subset to just April 1st, 2014.
snotel_ut <- rsnodas::april_1_snotel_data
snotel_ut_2014 <- snotel_ut[snotel_ut$DATE == "2014-04-01", ]
```

## Download PRISM climate data

The PRISM climate group has been provided climate maps since 1895 for the Precipitation (PPT), Minimum and maximum temperature (Tmin and Tmax), Minimum and maximum vapor pressure deficit (vpdmin and vpdmax), mean dew point (tdmean), Elevation (Elev), Total global shortwave solar radiation.

Most of this data from PRISM can be downloaded by utilizing the R package, \texttt{prism}, and more examples and information is available at \href{https://cran.r-project.org/web/packages/prism/vignettes/prism.html}{\textcolor{blue}{this link}}. The function `download_prism` can be used to download and store PRISM climate data that can be utilized later for model prediction. These are examples of downloading daily, monthly, and yearly data from separate years and multiple types and the store them in the directory.

Downloading PRISM can also be completed using rsnodas by using download_prism. This is just one function that can download daily, monthly, or yearly PRISM maps.
```{r prism, eval = FALSE}
prism::prism_set_dl_dir(paste0(getwd(), "/data-raw/prism"))

# Download the 4km resolution of the 30-year average precipitation for the months of March and April
prism::get_prism_normals(type = "ppt", resolution = "4km",
                         mon = 3:4, keepZip = FALSE)

# Download the 30-year annual average precip and annual average temperature
prism::get_prism_normals("ppt", "4km", annual = TRUE, keepZip = FALSE)

```

```{r prism2, eval = FALSE, echo = TRUE}
## NOT RUN, This was ran earlier 
# Example of downloading 4km monthly precipitation maps from Dec. 2013 - Feb. 2014 
download_prism(sp_res = "4km", data = c("ppt"), t_res = "monthly",
               start_date = as.Date("2013-12-01"), end_date = as.Date("2014-02-15"),  
               out_dir = "/Users/loganschneider/Desktop/GitHub/prism")

# Example of downloading daily 4km mean and max temperature maps for Jan. 1-2, 2004
download_prism(sp_res = "4km", data = c("tmax", "tmean"), t_res = "daily",
               start_date = as.Date("2013-11-15"), end_date = as.Date("2013-11-17"),
               out_dir = "/Users/loganschneider/Desktop/GitHub/prism")

# Example of downloading yearly Daily minimum and max vapor pressure deficit 
#   at 4km resolution maps for Jan. 1, 2017-2019
download_prism(sp_res = "4km", data = c("vpdmin", "vpdmax"), t_res = "yearly", 
               start_date = as.Date("2017-01-01"), end_date = as.Date("2019-01-15"),
               out_dir = "/Users/loganschneider/Desktop/GitHub/prism")

```

Note that all PRISM files need to be in the same location in order to use the function `gam_to_df` in the next section.

# GAM to Raster

After downloading the point data provided by SNOTEL sites and climate variables from PRISM.  The process of creating gridded raster estimates will be demonstrated.  This uses the function, `gam_to_raster` and accesses files in one directory. This allows users to explore different models and explore different climate variable combinations. 

```{r gam, eval = FALSE, echo = TRUE}
# creation of a data frame with all the PRISM variables of precipitation and elevation
gam_2014 <- gam_to_df(model_data = snotel_ut_2014,
                      raster_template = snodas_ut_2014,
                      path_to_prism = "/Users/loganschneider/Desktop/GitHub/prism",
                      model_x <- c("ppt_normal_annual", "elevation"),
                      model_y <- c("VALUE"),
                      coords = c("LONGITUDE", "LATITUDE"))

# This allows users to explore using different models with the same climate variables. 
model <- mgcv::gam(data = snotel_ut_2014,
                   VALUE ~ s(LONGITUDE, LATITUDE, bs = "sos", k = 25) +                          
                  s(ppt_normal_annual) +
                  s(elevation),
                method = "REML")

# After creating a model, we can make predictions with the information available.
gam_rast <- df_to_raster(model = model, df = gam_2014)

g <- ggplot() + 
  stars::geom_stars(data = gam_rast) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2014 GAM SWE predictions") + 
  scale_fill_viridis_c(option = "A") + 
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        text = element_text(size = 22))

```

\begin{figure}[ht]
\centerline{\includegraphics[width=.45\textwidth]{figures/GAM_SWE_map_2014.png}}
\end{figure}

## Station Density

Before we can start blending these maps together, there needs to be some kind of weight associated with both maps.  This is going to be accomplished by looking at observation or station density.  The `sigma` argument will extend the distance and is in meters while the gridded product is in kilometers.  Changing the `max_weight` argument gives more weight to the Generalized Additive model or the model from the in-situ measurements.  

```{r density, eval = FALSE, echo = TRUE}
dens_2014 <- points_to_density_stars(sp_points = snotel_ut_2014,
                                     coords = c("LONGITUDE", "LATITUDE"),
                                     raster_template = snodas_ut_2014,
                                     sigma = 15000,
                                     max_weight = .80,
                                     flat_crs = "+proj=utm + zone=12 + datum=WGS84")

ggplot() + 
  stars::geom_stars(data = dens_2014) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2014_Station_Density") + 
  scale_fill_viridis_c(option = "B") + 
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        text = element_text(size = 22))

```

\begin{figure}[ht]
\centerline{\includegraphics[width=.45\textwidth]{figures/Thesis_Station_Density_2014.png}}
\end{figure}

The weighting scheme can change in the future.

## Ensemble SNODAS and GAM predictions

Lastly, you can use all the previous maps to create a final prediction or estimate of SWE. This process can be applied to multiple types of spatial problems. 

```{r ensemble, eval = FALSE, echo = TRUE}
comb_map <- ((dens_2014) * gam_rast) +
    ((1 - dens_2014) * snodas_ut_2014)

g <- ggplot() + 
  stars::geom_stars(data = comb_map) +
  geom_sf(data = ut_map, fill = "NA", size = 1, color = "blue") +
  ggtitle("2014 Ensemble Map") + 
  scale_fill_viridis_c(option = "B") + 
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        text = element_text(size = 22))

```

\begin{figure}[ht]
\centerline{\includegraphics[width=.45\textwidth]{figures/Thesis_Ensemble_2014.png}}
\end{figure}

<!-- \begin{figure} -->
<!-- \centering -->
<!-- \begin{subfigure}{.5\textwidth} -->
<!--   \centering -->
<!--   \includegraphics[width=.4\linewidth]{image1} -->
<!--   \caption{A subfigure} -->
<!--   \label{fig:sub1} -->
<!-- \end{subfigure}% -->
<!-- \begin{subfigure}{.5\textwidth} -->
<!--   \centering -->
<!--   \includegraphics[width=.4\linewidth]{image1} -->
<!--   \caption{A subfigure} -->
<!--   \label{fig:sub2} -->
<!-- \end{subfigure} -->
<!-- \caption{A figure with two subfigures} -->
<!-- \label{fig:test} -->
<!-- \end{figure} -->
